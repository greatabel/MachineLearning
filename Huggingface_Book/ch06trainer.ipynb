{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83bc87ae-b8aa-4ae1-b42d-3e2e3655f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='hfl/rbt3', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('hfl/rbt3')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007be06f-8230-484c-a5d4-da307825adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3209, 3299, 6163, 7652, 749, 872, 4638, 4970, 2094, 102], [101, 872, 6163, 7652, 749, 1166, 782, 4638, 3457, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(\n",
    "    ['明月装饰了你的窗子', '你装饰了别人的梦'],\n",
    "    truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a2b011-fc34-4077-9c2f-a0e3ed38a2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "\n",
    "#缩小数据规模，便于测试\n",
    "dataset['train'] = dataset['train'].shuffle().select(range(2000))\n",
    "dataset['test'] = dataset['test'].shuffle().select(range(100))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d54f392-fa84-46da-9977-298fbb9a720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f11c85ab2e4c94b700854210be6d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c974f7c59104c7f9cc079fe845fc454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/编码\n",
    "def f(data):\n",
    "    return tokenizer.batch_encode_plus(data['text'], truncation=True)\n",
    "\n",
    "\n",
    "dataset = dataset.map(f,\n",
    "                      batched=True,\n",
    "                      batch_size=1000,\n",
    "                      num_proc=4,\n",
    "                      remove_columns=['text'])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab5c8eb-e2a3-42a4-a901-262d8b459a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed5f325cbba44b98696a313714a9d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2523af7e70e8415c85280d2c8b40b4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1984\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 99\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(data):\n",
    "    return [len(i) <= 512 for i in data['input_ids']]\n",
    "\n",
    "\n",
    "dataset = dataset.filter(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03491e0f-78b4-4a7d-92ed-fff7fb12ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3847.8338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/加载模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3',\n",
    "                                                           num_labels=2)\n",
    "\n",
    "#统计模型参数量\n",
    "sum([i.nelement() for i in model.parameters()]) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbcc038-279d-40bf-ba28-9883562e02c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5686, grad_fn=<NllLossBackward0>), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#模拟一批数据\n",
    "data = {\n",
    "    'input_ids': torch.ones(4, 10, dtype=torch.long),\n",
    "    'token_type_ids': torch.ones(4, 10, dtype=torch.long),\n",
    "    'attention_mask': torch.ones(4, 10, dtype=torch.long),\n",
    "    'labels': torch.ones(4, dtype=torch.long)\n",
    "}\n",
    "\n",
    "#模型试算\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a855854a-c5d0-44e0-bb2d-f67dd7be8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e13b4228-af02-41ab-81db-4968c396f300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/定义评价函数\n",
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = logits.argmax(axis=1)\n",
    "    return {'accuracy': (logits == labels).sum() / len(labels)}\n",
    "    #return metric.compute(predictions=logits, references=labels)\n",
    "\n",
    "\n",
    "#模拟输出\n",
    "eval_pred = EvalPrediction(\n",
    "    predictions=np.array([[0, 1], [2, 3], [4, 5], [6, 7]]),\n",
    "    label_ids=np.array([1, 1, 0, 1]),\n",
    ")\n",
    "\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44be83da-be0d-4367-8165-22d1e8d6aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/定义训练参数\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "#定义训练参数\n",
    "args = TrainingArguments(\n",
    "    #定义临时数据保存路径\n",
    "    output_dir='./output_dir',\n",
    "\n",
    "    #定义测试执行的策略，可取值no、epoch、steps\n",
    "    evaluation_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step执行一次测试\n",
    "    eval_steps=30,\n",
    "\n",
    "    #定义模型保存策略，可取值no、epoch、steps\n",
    "    save_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step保存一次\n",
    "    save_steps=30,\n",
    "\n",
    "    #定义共训练几个轮次\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    #定义学习率\n",
    "    learning_rate=1e-4,\n",
    "\n",
    "    #加入参数权重衰减，防止过拟合\n",
    "    weight_decay=1e-2,\n",
    "\n",
    "    #定义测试和训练时的批次大小\n",
    "    per_device_eval_batch_size=16,\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    #定义是否要使用gpu训练\n",
    "    no_cuda=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5854fbc1-c3c4-43f9-9141-b6e21168c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/定义训练器\n",
    "from transformers import Trainer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "#定义训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41eeb1e8-f7ff-4c6f-b7b1-9490de4a56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "29\n",
      "287\n",
      "56\n",
      "52\n",
      "input_ids torch.Size([5, 287])\n",
      "token_type_ids torch.Size([5, 287])\n",
      "attention_mask torch.Size([5, 287])\n",
      "labels torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "#第6章/测试数据整理函数\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "#获取一批数据\n",
    "data = dataset['train'][:5]\n",
    "\n",
    "#输出这些句子的长度\n",
    "for i in data['input_ids']:\n",
    "    print(len(i))\n",
    "\n",
    "#调用数据整理函数\n",
    "data = data_collator(data)\n",
    "\n",
    "#查看整理后的数据\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7a57b8-d746-42ec-aed6-fb4b42875a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 拉 拉 1 很 早 就 买 过 了 ， 第 一 遍 读 是 看 热 闹 、 看 情 节 ； 等 到 再 次 阅 读 的 时 候 ， 已 将 书 中 所 罗 列 的 职 场 要 点 贴 上 标 记 。 其 实 本 书 意 在 总 结 作 者 在 职 场 中 的 经 验 以 及 技 巧 ， 但 高 明 之 处 在 于 她 将 所 有 的 教 条 融 汇 于 一 个 生 动 的 故 事 中 ， 并 塑 造 了 一 个 鲜 活 的 白 领 形 象 。 拉 拉 2 与 1 的 区 别 在 于 ， 1 中 故 事 情 节 更 加 跌 宕 ， 而 2 更 侧 重 于 职 场 经 验 的 总 结 。 总 之 ， 是 本 好 书 的 同 时 ， 可 以 教 会 我 们 不 少 东 西 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50276e7d-1861-48de-a901-31bfb0856d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7114213705062866,\n",
       " 'eval_accuracy': 0.5050505050505051,\n",
       " 'eval_runtime': 4.4101,\n",
       " 'eval_samples_per_second': 22.449,\n",
       " 'eval_steps_per_second': 1.587}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d832efa9-e9a6-4d70-ad61-c048aac9cdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.423485</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.384137</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.395534</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392675</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=0.3901086930305727, metrics={'train_runtime': 43.9915, 'train_samples_per_second': 45.1, 'train_steps_per_second': 2.819, 'total_flos': 68960599001280.0, 'train_loss': 0.3901086930305727, 'epoch': 1.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3743df3f-7250-48c3-bd94-f683185e1a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380434</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=0.07492614561511625, metrics={'train_runtime': 6.8956, 'train_samples_per_second': 287.721, 'train_steps_per_second': 17.983, 'total_flos': 68960599001280.0, 'train_loss': 0.07492614561511625, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/从某个存档继续训练\n",
    "trainer.train(resume_from_checkpoint='./output_dir/checkpoint-90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f700fcb-c7e4-455e-8436-b73f50b2ddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.37950029969215393,\n",
       " 'eval_accuracy': 0.8787878787878788,\n",
       " 'eval_runtime': 0.4722,\n",
       " 'eval_samples_per_second': 209.664,\n",
       " 'eval_steps_per_second': 14.825,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40cbfff6-b544-4209-bd5c-2092c8f17b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/手动保存模型参数\n",
    "trainer.save_model(output_dir='./output_dir/save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "874b72ba-8cd0-4f42-b4c4-65b288d1ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# 假设您知道模型的类型或配置\n",
    "model = AutoModel.from_pretrained('./output_dir/save_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "930f5713-809d-44ba-9805-f6433ef5b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为 了 白 彦 的 死 ， 伤 心 了 好 久 。 很 久 没 有 为 了 一 本 书 。 为 了 一 本 书 里 那 些 如 此 贴 近 生 活 的 文 字 而 感 动 伤 心 了 。 喜 欢 宁 默 的 潇 洒 ， 刚 开 始 的 时 候 还 在 为 他 们 两 个 在 面 对 爱 情 时 的 清 醒 而 不 解 。 最 后 直 到 白 彦 意 外 死 后 出 现 的 地 图 ， 宁 默 的 反 应 。 才 知 道 原 来 他 们 都 爱 彼 此 爱 的 那 么 深 。 。 。 。 想 起 了 宁 默 那 句 话 ， 她 跟 梁 葳 葳 说 她 宁 愿 输 给 她 ， 输 给 任 何 人 也 不 想 输 给 生 离 死 别 。 。 。 。\n",
      "label= Not available\n",
      "predict= 0\n",
      "指 纹 、 蓝 牙 都 有 ， 又 是 独 显 ， 这 个 价 格 也 是 市 面 上 最 低 ， 很 实 惠 。 送 货 上 门 很 方 便 很 放 心 。\n",
      "label= Not available\n",
      "predict= 1\n",
      "有 了 第 一 本 书 的 铺 垫 ， 读 第 二 本 的 时 候 开 始 进 入 状 态 。 基 本 上 第 二 本 就 围 绕 主 角 们 的 能 力 训 练 展 开 ， 故 事 的 主 要 发 生 场 地 设 置 在 美 洲 的 亚 马 逊 丛 林 。 心 里 一 直 疑 惑 这 和 西 藏 有 什 么 关 系 ， 不 过 大 概 看 完 全 书 才 能 知 道 内 里 的 线 索 。 其 中 描 述 了 很 多 热 带 雨 林 中 特 有 的 神 秘 动 植 物 以 及 一 些 生 存 技 巧 和 常 识 ， 受 益 匪 浅 。 能 够 想 像 出 要 写 这 样 一 部 书 ， 融 合 这 样 许 多 的 知 识 ， 作 者 需 要 花 费 多 少 心 血 来 搜 集 和 整 理 并 成 文 。\n",
      "label= Not available\n",
      "predict= 0\n",
      "和 其 他 netbook 比 起 来, 这 款 机 器 还 是 有 点 贵 的. 另 外 大 陆 始 终 没 有 引 进 高 分 屏 的 版 本, 很 遗 憾. 升 级 内 存 需 要 拆 键 盘, 对 一 般 用 户 可 能 会 是 个 问 题.\n",
      "label= Not available\n",
      "predict= 1\n",
      "相 对 其 他 一 线 品 牌 价 格 低, 配 置 也 均 衡, xp 很 容 易 装, 跟 普 通 装 电 脑 没 两 量, 给 后 来 买 的 朋 友 一 点 建 议 吧, 用 深 度 的 xp, 按 f2 进 入 bois, 设 置 光 驱 启 动, 这 个 懂 吧 / 然 后 跟 平 时 安 装 xp 差 不 多, 可 能 大 家 用 ghost 比 较 多, 关 于 分 区 安 装 盘 微 软 已 经 自 带 了, 很 方 便, 关 键 安 装 的 光 盘 要 带 sata 口 的 驱 程, 建 议 用 深 度 6. 2 或 者 雨 林, 其 他 驱 程 网 上 很 多, 不 行 的 话 查 acer 的 tai wan 网 站, 不 懂 的 话 pm 我.\n",
      "label= Not available\n",
      "predict= 1\n",
      "买 前 看 规 格 介 绍 是 6 芯 电 池 ， 实 物 却 是 3 芯 ， 这 点 是 很 大 的 不 足 ， 希 望 京 东 能 组 织 原 装 6 芯 电 池 供 应 。\n",
      "label= Not available\n",
      "predict= 0\n",
      "买 来 后 ， 宝 宝 不 喜 欢 ， 我 也 不 喜 欢 。 说 这 书 如 南 橘 北 枳 ， 是 因 为 小 朋 友 的 书 教 的 是 日 常 生 活 中 常 见 事 物 ， 可 是 这 套 书 比 如 很 多 车 ， 是 在 国 外 有 的 ， 在 中 国 根 本 没 有 ， 也 不 是 这 么 叫 法 ， 告 诉 他 这 些 陌 生 的 ， 翻 译 过 来 的 东 西 有 什 么 用 呢 ？ 在 中 国 看 不 见 ； 在 国 外 ， 也 听 不 懂 。 还 不 如 ， 保 留 原 来 的 英 文 ， 不 要 翻 译 还 更 实 用 呢 ！\n",
      "label= Not available\n",
      "predict= 0\n",
      "是 因 为 陈 丹 青 在 谈 鲁 迅 时 的 推 荐 ， 才 留 意 这 本 书 并 找 来 看 的 ， 确 实 很 生 动 、 有 趣 ， 应 该 感 谢 胡 颂 平 先 生 （ 尽 管 他 很 谦 逊 ） ， 为 后 人 记 录 了 这 些 精 彩 的 片 段 ， 在 大 师 人 生 的 最 后 几 年 。 过 他 的 记 录 ， 才 感 觉 到 ， 原 来 胡 适 并 不 只 是 一 个 高 高 在 上 、 后 人 激 赏 抑 或 针 砭 的 名 人 ， 而 是 真 真 切 切 的 离 我 们 很 近 很 近 的 一 位 智 者 ， 一 位 有 血 有 肉 的 大 师 。\n",
      "label= Not available\n",
      "predict= 0\n",
      "1. 外 观 小 巧 ， 靓 丽 。 机 器 应 该 是 珠 光 白 ， 有 光 的 时 候 会 略 有 珠 光 的 反 射 。 2. 机 器 配 置 对 与 女 孩 子 来 说 足 够 了 ， 考 了 部 720p ， 4g 左 右 的 电 影 文 件 ， 播 放 流 畅 没 有 延 迟 问 题 。 3. 无 限 网 卡 的 信 号 很 稳 定 ， 满 意\n",
      "label= Not available\n",
      "predict= 1\n",
      "一 如 既 往 的 支 持 ， 不 错 的 酒 店 ， 服 务 上 再 上 去 一 点 就 好 了 。 宾 馆 反 馈 2008 年 7 月 31 日 ： 谢 谢 您 长 期 以 来 对 我 酒 店 的 关 心 和 支 持 ， 我 酒 店 即 将 申 报 四 星 级 酒 店 ， 我 们 在 硬 件 的 改 造 的 同 时 ， 软 件 服 务 上 也 加 强 和 提 升 ， 争 取 让 每 一 位 宾 客 都 满 意 。 我 酒 店 按 五 星 级 标 准 装 修 的 24 - 26 楼 高 层 观 景 客 房 即 将 竣 工 ， 期 待 您 的 光 临 ！ ！\n",
      "label= Not available\n",
      "predict= 1\n",
      "小 巧 ， 电 池 强 劲 。 720p 的 电 影 都 能 正 常 观 看 。 不 玩 大 型 3d 游 戏 的 话 。 日 常 应 用 足 够 了 。 送 货 速 度 很 快 。\n",
      "label= Not available\n",
      "predict= 1\n",
      "明 显 能 看 出 来 是 低 端 本 ， 塑 料 感 很 强 ， 做 工 也 仅 仅 比 神 船 稍 好 。 usb 只 有 2 个 ， 且 都 在 左 边 。 散 热 很 差 ， c 面 好 像 蒸 笼 啊 。 不 送 包\n",
      "label= Not available\n",
      "predict= 0\n",
      "屏 幕 上 有 一 个 坏 点 ， 夜 间 测 试 ， 硬 盘 滴 答 滴 答 的 响 。 后 面 的 螺 丝 都 有 卸 过 的 痕 迹 ， 让 人 有 种 不 放 心 的 感 觉 ！ 京 东 多 的 东 西 都 送 了 ， 一 个 鼠 标 也 表 现 得 那 么 吝 啬 。\n",
      "label= Not available\n",
      "predict= 0\n",
      "作 者 妙 语 连 珠 ， 将 整 个 60 - 70 年 代 用 层 出 不 穷 的 摇 滚 巨 星 与 自 身 故 事 紧 紧 相 连 什 么 是 乡 愁 ？ 什 么 是 摇 滚 ？ 那 是 一 种 特 立 独 行 看 似 高 傲 实 则 温 暖 的 姿 态 那 是 一 种 绝 世 独 立 下 深 深 的 孤 单 与 不 甘 文 字 和 音 乐 当 两 种 忧 愁 相 互 碰 撞 的 时 候 才 会 激 起 读 者 心 中 的 相 同 感 受 ， 无 论 何 时 ， 世 界 在 变 ， 我 们 的 偶 像 在 慢 慢 老 去 那 个 曾 经 年 华 不 老 的 时 代 已 然 飘 去 。 于 是 摇 滚 ， 成 了 最 让 人 痛 彻 心 扉 的 蓝 调\n",
      "label= Not available\n",
      "predict= 0\n",
      "首 先 附 赠 软 件 （ office2007 、 mcafee ） 是 在 第 一 次 启 动 时 决 定 是 否 安 装 。 不 像 很 多 品 牌 的 笔 记 本 ， 一 上 来 一 股 脑 儿 给 你 装 上 。 而 且 实 际 使 用 后 发 现 它 的 很 多 自 带 的 实 用 软 件 非 常 出 色 ， 非 常 人 性 化 ！ 回 家 仔 细 使 用 后 发 现 键 盘 手 感 果 然 如 大 家 所 说 非 常 出 色 。 另 外 第 一 次 使 用 小 红 点 就 爱 上 它 了 - - 感 觉 比 触 摸 板 好 多 了 ， 难 怪 它 会 成 为 thinkpad 基 因 之 一 机 器 虽 然 有 点 重 ， 但 是 感 觉 很 扎 实 ， 比 某 些 娱 乐 本 扎 实 很 多 。\n",
      "label= Not available\n",
      "predict= 1\n",
      "键 盘 还 是 要 贴 膜 才 好, 内 存 问 题, 我 基 本 不 玩 游 戏, 不 需 要 那 么 多 内 存. 再 说 内 存 便 宜, 都 不 是 问 题.\n",
      "label= Not available\n",
      "predict= 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(trainer.get_eval_dataloader()):\n",
    "    break\n",
    "\n",
    "# 移除data字典中的'labels'键\n",
    "labels = data.pop('labels', None)\n",
    "\n",
    "for k, v in data.items():\n",
    "    data[k] = v.to(device)\n",
    "\n",
    "num_labels = 3\n",
    "# 假设classifier是一个额外的线性层，用于生成logits\n",
    "classifier = torch.nn.Linear(model.config.hidden_size, num_labels)\n",
    "\n",
    "out = model(**data)\n",
    "predicted_labels = logits.argmax(dim=1)\n",
    "\n",
    "for i in range(16):\n",
    "    print(tokenizer.decode(data['input_ids'][i], skip_special_tokens=True))\n",
    "\n",
    "    # 检查是否存在'labels'键\n",
    "    if 'labels' in data:\n",
    "        print('label=', data['labels'][i].item())\n",
    "    else:\n",
    "        print('label= Not available')\n",
    "\n",
    "    print('predict=', predicted_labels[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e75acc-3da9-4e9b-9e63-57b96240c8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
