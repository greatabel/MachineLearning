1.我想问一下spleeter和vocano模型的具体结构和参数

Spleeter是一个基于深度学习的音频分离工具，使用的模型结构是堆叠式U-Net，
包含多个卷积层和反卷积层，并使用随机梯度下降算法进行训练。

参数上：Spleeter使用的堆叠式神经网络有5个卷积层和5个反卷积层。
每个卷积层包括一个3x3的卷积核和一个ReLU激活函数，
每个反卷积层包括一个2x2的反卷积核和一个ReLU激活函数

vocano 主要食用深度卷积神经网络（CNN）结构来学习音频信号的特征表示，
并使用多通道注意力机制来聚焦于声乐和伴奏信号的频谱特征

参数上vocano 中使用的主要超参数：
学习率、
批量大小、
权重衰减、
梯度裁剪和噪声添加


2. 把musdb18的结构
MusDB18是一个包含18首歌曲的音乐数据库，其中每首歌曲都有多个音轨，
里面有各个音轨分离出来，如鼓、吉他、贝斯、和声等


3.musdb18训练的细节也说一下
数据准备：首先需要从MusDB18中选择一组训练数据，通常会将数据按比例分成测试集验证集。
对于每个音频文件，需要将其分解成多个音轨，并将它们存储为单独的音频文件。
可以使用Spython调用pleeter提供的库接口来自动化这个过程。

模型选择：Spleeter使用深度学习模型来进行音频分离，支持多种模型结构，
我们选择的是2stems模型等。

模型训练：在选择好模型之后，需要使用训练数据对模型进行训练。在训练过程中
，需要设置训练的参数，在gpu上训练（本地或云端）。

模型评估：在模型训练完成后，需要使用验证集和测试集对模型进行评估。
在评估过程中，通常会使用一些常见的评估指标，如信噪比（SNR）、SIR,SAR等指标进行度量

时间看数据量，我们选择5-6首歌，一般也要小时级别的时间训练在服务器端（rtx2080ti）


4. 哪2个数据库
除去 musdb18 数据集
后来我还下载了DSD100
https://www.loria.fr/~aliutkus/DSD100subset.zip 数据集