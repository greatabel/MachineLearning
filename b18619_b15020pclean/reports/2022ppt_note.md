# ppt第3页

去年的ppt，我们研究了不同类型的模型以及如何为我们的问题创建模型。 
我们还看到了当我们改变其他一些变量的概率时，变量的概率是如何变化的。
本次新的ppt中，我们将讨论可用于计算这些概率变化的各种算法。 

我们还将了解如何使用这些推理算法根据我们的模型预测新数据点的变量值，该模型是使用我们之前的数据进行训练的。
第3页主要是讲解：条件概率的推断

# 第4页-5页
第4页是推断结果的预测结果展示
第5页 讲怎么通过pgmpy 实现我们的推断算法


# 第6-8页
是可视化部分，主要是给予graphviz实现可视化

比如可视化的例子的理解：考虑一下医院位置的例子，如上图所示。 
我们可以考虑可以在模型上尝试的各种推理查询。 
例如，假设位置好、成本高、数量多，我们可能想找到一家医院质量好的概率。
的人来也素质高，这将导致概率查询
P（Q = 好 | L= 好，C = 高，N = 高）。 另外，如果我们想到一个机器学习问题，
如果我们想在给定其他变量的情况下预测到医院的人数，这将只是对模型的推理查询，
而具有更高概率的状态将是模型的预测。 现在，让我们看看如何从模型中计算这些条件概率。


# 9-10页
计算两条数据相似性时，sklearn.K-Means默认用欧式距离
虽然还有余弦相似度，马氏距离等多种方法，但没有设定计算距离方法的参数。

# 11-13页
TfidfVectorizer背后调用的cosine_similarity就是计算L2归一化的向量点乘。
如果x,y是行向量，它们是计算 cosine similarity
具体可以看：
https://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity

scikit-learn 是一个基于Python的Machine Learning模块，
里面给出了很多Machine Learning相关的算法实现，其中就包括K-Means算法。
在做K-Means聚类之前，我们首先需要对将文本转化成向量的形式，转换文本的第一步，自然是分词，
分完词过后再将词转换成向量，或者说转换成Bag-of-words模型，这里可以采用TF-IDF算法